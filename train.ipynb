{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/kahxuan/chinese-calligraphy-recognition/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7yV-6LBB0w-s",
    "outputId": "5ebd552a-5805-4848-a9ba-9aab9350804b"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/kahxuan/chinese-calligraphy-ocr.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TwET8wlG1v3I",
    "outputId": "fa473010-b722-4d29-9bf8-061c9ac6dc44"
   },
   "outputs": [],
   "source": [
    "%cd chinese-calligraphy-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_93TTOBJ0v3l"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from modules.model import CRModel, IMG_SIZE, INPUT_SHAPE\n",
    "\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "config_path = 'config.yaml'\n",
    "\n",
    "with open(config_path) as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "data_path = config['dataset']['raw_dir']\n",
    "config = config['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J81EFjLg0v3w",
    "outputId": "e647c3a3-5df8-4595-d330-acab2bd60b83"
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "train = image_dataset_from_directory('data/train', \n",
    "                                     seed=config['dataset']['seed'],\n",
    "                                     shuffle=True, \n",
    "                                     batch_size=config['batch_size'], \n",
    "                                     image_size=IMG_SIZE, \n",
    "                                     label_mode='categorical'\n",
    "                                    )\n",
    "val = image_dataset_from_directory('data/validation', \n",
    "                                   seed=config['dataset']['seed'],\n",
    "                                   shuffle=True, \n",
    "                                   batch_size=config['batch_size'], \n",
    "                                   image_size=IMG_SIZE, \n",
    "                                   label_mode='categorical'\n",
    "                                  )\n",
    "\n",
    "test = image_dataset_from_directory('data/test', \n",
    "                                   seed=config['dataset']['seed'],\n",
    "                                   shuffle=True, \n",
    "                                   batch_size=config['batch_size'], \n",
    "                                   image_size=IMG_SIZE, \n",
    "                                   label_mode='categorical'\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CRModel(num_class=config['num_class'])\n",
    "model.build(input_shape=tuple(INPUT_SHAPE))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=config['optimizer']['lr']),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6oToguP0v31"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train, validation_data=val, epochs=config['epochs'])\n",
    "loss, accuracy = model.evaluate(test)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M1izs5c76Z9o"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,2.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "images = []\n",
    "data = test.as_numpy_iterator()\n",
    "\n",
    "for step in range(len(test)):\n",
    "    X, y = data.next()\n",
    "    y_true += list(y)\n",
    "    y_pred += list(model.predict(X))\n",
    "    images += list(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_top1 = tf.keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=1)\n",
    "acc_top3 = tf.keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=1)\n",
    "print('Top 1 acc', acc_top1)\n",
    "print('Top 3 acc', acc_top3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zpOcta3i2dWH",
    "outputId": "9f392c0a-1c69-4cc0-cdbe-f040bc0341eb"
   },
   "outputs": [],
   "source": [
    "idx = np.where(y_true != y_pred)[0]\n",
    "random.shuffle(idx)\n",
    "idx = idx[16]\n",
    "\n",
    "labels = [np.argmax(y_true[i]) for i in idx]\n",
    "preds = [np.argmax(y_pred[i]) for i in idx]\n",
    "\n",
    "print('Predictions', ' '.join([train.class_names[pred] for pred in preds]))\n",
    "print('Labels     ', ' '.join([train.class_names[label] for label in labels]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 597
    },
    "id": "6NqIWTCr65te",
    "outputId": "1f922291-2cc7-4064-a497-4fcfe130277d"
   },
   "outputs": [],
   "source": [
    "chinese_font = mpl.font_manager.FontProperties(fname='fonts/heiti.ttf')\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(16):\n",
    "    ax = plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(images[i].astype(\"uint8\"))\n",
    "    plt.title(train.class_names[np.argmax(y_pred[i])], fontproperties=chinese_font, fontsize=20)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "106DsQqJGc7_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
